<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html><head>
   
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
    
    <link href="assets/styles_2021.css" rel="stylesheet">
    <title>Zexiang Xu's homepage</title>
    
    <!-- TODO: google analytics -->
  </head>

  <body>
    

    <div id="menu" class="navbar" >
      <div class="nav-left">Zexiang Xu's homepage </div>
      <a href="">Home</a>
      <a href="#news">News</a>
      <a href="#pub">Publication</a>
      <a href="#community">Service</a>
    </div>

    <div id="container">
      <div class="card-block light">
        <div class="paper" id="self">
        <div class="avatar">
          <img src="images/me.jpg">
        </div>

        <div class="basic">
          <h1>Zexiang Xu (徐泽祥)</h1>
          <div class="bio">
           VP of R&D at Hillbot Inc.
          </div>
          <br>
          <div class="bio">
            zexiangxu AT gmail.com
        </div>
        <br>
        <div class="bio">
            <a href="">[CV]</a>
            <a href="https://scholar.google.com/citations?user=_RRIYvEAAAAJ&hl=en&oi=ao">[Google Scholar]</a>
            <a href="https://x.com/zexiangxu">[Twitter]</a> 
          </div>
          
        </div>
        <div style="clear: both; padding: 0"></div>
    </div>
      </div>

      <div id="bio" class="card-block dark">
        <br/><br/>
        <p>
            I am Vice President of Research and Development at <a href = "https://www.hillbot.ai/">Hillbot</a>, where I mainly work on multimodal foundation models for robotics and embodied AI.
            Prior to joining Hillbot, I was a research scientist at Adobe Research, working on neural 3D, 3D large models, and GenAI foundation models. Before that, I obtained my Ph.D. at University of California, San Diego, advised by <a href = "https://cseweb.ucsd.edu/~ravir/">Prof. Ravi Ramamoorthi</a>. 
            <br/><br/>
            My research lies at the intersection of computer vision, computer graphics, machine learning, and AI foundation models. My previous work has broadly covered 3D reconstruction, 3D generation, neural representations, view synthesis, relighting, appearance modeling, and appearance acquisition.<br/>

            </p>
    </div>
    

      <hr class="style-two">
      <div id="news" class="card-block dark">
          <h2>News</h2>
          <div>
              <ul>
                <li>
                    <b style="color: #39b8f3;font-size: 1.2em;">NEW!</b> [Feb, 2025] Four papers are accepted to CVPR 2025. 
                </li>
                <li>
                    <b style="color: #39b8f3;font-size: 1.2em;">NEW!</b> [Jan, 2025] Two papers, one oral and one spotlight, are accepted to ICLR 2025. 
                </li>
                <li>
                    <b style="color: #39b8f3;font-size: 1.2em;">NEW!</b> [Dec, 2024] I left Adobe and joined <a href = "https://www.hillbot.ai/">Hillbot</a> as VP of Research and Development. 
                </li>
                <li>
                    <b style="color: #39b8f3;font-size: 1.2em;">NEW!</b> [Sep, 2024] I will serve as an Area Chair for CVPR 2025. 
                </li>
                <li>
                    <b style="color: #39b8f3;font-size: 1.2em;">NEW!</b> [Sep, 2024] Three papers are accepted to NeurIPS 2024. 
                </li>
                <li>
                    <b style="color: #39b8f3;font-size: 1.2em;">NEW!</b> [July, 2024] Two papers are accepted to ECCV 2024. 
                </li>
                <li>
                    <b style="color: #39b8f3;font-size: 1.2em;">NEW!</b> [Mar, 2024] I'm co-organizing the 1st workshop on 3D foundation models (<a href="https://3dfm.github.io/">3dfm.github.io</a>) at CVPR 2024. 
                </li>
                <li>
                    <b style="color: #39b8f3;font-size: 1.2em;">NEW!</b> [Feb, 2024] I gave talks at UIUC, University of Tübingen, and Oregon State University on 3D AI GenTech.
                </li>
                <li>
                    <b style="color: #39b8f3;font-size: 1.2em;">NEW!</b> [Feb, 2024] One paper is accepted to CVPR 2024 as a highlight presentation! 
                </li>
                <li>
                    <b style="color: #39b8f3;font-size: 1.2em;">NEW!</b> [Jan, 2024] Four papers are accepted to ICLR 2024 and three of them are selected as spotlight presentations! 
                </li>
                <li>
                    [Nov, 2023] I finally opened my twitter account. Let's connect <a href="https://x.com/zexiangxu">@zexiangxu</a> ! 
                </li>
                <li>
                    [Sep, 2023] Two papers are accepted to NeurIPS 2023. 
                </li>
                <li>
                     [Aug, 2023] One paper gets conditionally accepted to SIGGRAPH Asia 2023. 
                </li>
                <li>
                    [July, 2023] One paper gets accepted to ICCV 2023. 
                </li>
                <li>
                    [Mar, 2023] Two papers are accepted to SIGGRAPH 2023. 
                </li>
                <li>
                     [Feb, 2023] Two papers are accepted to CVPR 2023. 
                </li>
                <li>
                     [Dec, 2022] I will serve as an Area Chair for ICCV 2023. 
                </li>
                
                
                  
                  
              </ul>
          </div>
          <span style="color: #83b2d8">
            <a data-bs-toggle="collapse" data-bs-target="#oldnews" aria-expanded="false" aria-controls="oldnews">More</a>
              <!-- <div class="indicator">+</div> -->
          </span>
          <div class="collapse" id="oldnews">
              <ul>
                <li>
                    [Aug, 2022] One paper gets accepted to Siggraph Asia 2022. 
               </li>
               <li>
                   [July, 2022] Three papers get accepted to ECCV 2022; TensoRF gets 3 strong accepts in the final review. 
               </li>
                <li>
                    [Mar, 2022] One paper gets accepted to SIGGRAPH 2022. 
                </li>
                  <li>
                    [Mar, 2022] Four papers (two oral presentations) get accepted to CVPR 2022! 
                  </li>
                <li>
                    [July 30, 2021] One paper gets accepted to SIGGRAPH Asia 2021.
                </li>
                <li>
                  [Jun 18, 2021] One paper gets accepted to TOG 2022.
              </li>
              <li>
                  [July 22, 2021] MVSNeRF gets accepted to ICCV 2021.
              </li>
                  <li>
                      [Jun 8, 2021] One paper gets accepted to EGSR 2021.
              </li>
              <li>
                  [May 21, 2021] I am a recipient of the 2021 <a href="https://gpsa.ucsd.edu/grad-resources/awards/chancellors-dissertation-medal.html"> Chancellor's Dissertation Medal </a> of UCSD!
              </li>
                  <li>
                      [Mar 26, 2021] Two papers get accepted to SIGGRAPH 2021.
                  </li>
                  <li>
                      [Mar 1, 2021] Two papers (both oral) get accepted to CVPR 2021.
                  </li>
                  <li>
                      [July 31, 2020] One paper gets accepted to SIGGRAPH Asia 2020.
                  </li>
                  <li>
                    [July 6, 2020] I joined Adobe Research as a research scientist.
                </li>
                  <li>
                      [July 2, 2020] Two papers (one spotlight) get accepted to ECCV 2020.
                  </li>
                  
                  <li>
                      [May 27, 2020] One paper gets accepted to EGSR 2020 (CGF track).
                  </li>
                  <li>
                      [Feb 2, 2020] Two papers (one oral) get accepted to CVPR 2020.
                  </li>
                  <li>
                    [Jul 29, 2019] One paper gets accepted to SIGGRAPH Asia 2019.
                  </li>
                  <li>
                      [Mar 25, 2019] Two papers get accepted to SIGGRAPH 2019.
                </li>
                <li>
                    [Nov 11, 2018] I'm honored to receive the 2019 <a href="https://research.adobe.com/fellowship/"> Adobe Research Fellowship </a>.
                  </li>
                  <li>
                    [Aug 11, 2018] One paper gets accepted to SIGGRAPH Asia 2018.
                  </li>
                  <li>
                    [Mar 26, 2018] One paper gets accepted to SIGGRAPH 2018.
                  </li>
                  <li>
                    [Feb 27, 2017] One paper gets accepted to CVPR 2017.
                  </li>
                  <li>
                    [Jul 23, 2016] One paper gets accepted to SIGGRAPH Asia 2016.
                  </li>
                  <li>
                    [Sep 27, 2015] I started as a Ph.D. student at UC San Diego.
                  </li>
                  <li>
                    [Aug 14, 2014] One paper gets accepted to SIGGRAPH Asia 2014.
                  </li>
              </ul>
          </div>
      </div>

      <hr class="style-two">
      <div id="community" class="card-block light">
        <h2>Service</h2>
        <li>Area Chair: ICCV 2023, CVPR 2025</li>
        <li>Paper Committee: Eurographics 2024; EGSR 2022-2024 </li>
        <li>Conference Reviewer: CVPR, ECCV, ICCV, ICLR, SIGGRAPH, SIGGRAPH Asia, Eurographics, Pacific Graphics,...</li>
        <li>Journal Reviewer: TOG, TIP, TPAMI, CGF...</li>
        <li>Workshop Organizer: <a href="https://3dfm.github.io/">3D foundation models (CVPR 2024)</a></li>
    </div>
    <hr class="style-two">
      <div class="card-block dark">
          <h2 id="pub">Selected Publications</h2>
      </br>
            *,† denotes equal contribution or advisory.

        

        <div id="papers">
            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    
                    <video width="90%" playsinline="" autoplay="" loop="" preload="" muted="">
                        <source src="papers/2024_LVSM/LVSM.mp4" type="video/mp4">
                    </video>
                    <!-- <img src="papers/2024_meshlrm/meshlrm.gif"> -->
                </div>
                <div class="description">
                    <div class="ptitle">
                        LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias</div>
                    <div class="pauthors">
                        Haian Jin, Hanwen Jiang, Hao Tan, Kai Zhang, Sai Bi, Tianyuan Zhang, Fujun Luan, Noah Snavely, <b>Zexiang Xu</b>
                    </div>
                    <div class="pvenue">ICLR 2025 (Oral)</div>
                    <div class="plinks">
                            <a href="https://arxiv.org/abs/2410.17242">[Paper]</a>
                            <a href="https://haian-jin.github.io/projects/LVSM/">[Project]</a>                            
                    </div>
                </div>
            </div>
            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    
                    <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                        <source src="papers/2024_longlrm/longlrm.mp4" type="video/mp4">
                    </video>
                    <!-- <img src="papers/2024_meshlrm/meshlrm.gif"> -->
                </div>
                <div class="description">
                    <div class="ptitle">Long-LRM: Long-sequence Large Reconstruction Model for Wide-coverage Gaussian Splats</div>
                    <div class="pauthors">
                        Ziwen Chen, Hao Tan, Kai Zhang, Sai Bi, Fujun Luan, Yicong Hong, Fuxin Li, <b>Zexiang Xu</b>
                    </div>
                    <div class="pvenue">arXiv 2024</div>
                    <div class="plinks">
                            <a href="https://arxiv.org/abs/2410.12781">[Paper]</a>
                            <a href="https://arthurhero.github.io/projects/llrm/">[Project]</a>                            
                    </div>
                </div>
            </div>
            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    
                    <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                        <source src="papers/2024_meshlrm/meshlrm.mp4" type="video/mp4">
                    </video>
                    <!-- <img src="papers/2024_meshlrm/meshlrm.gif"> -->
                </div>
                <div class="description">
                    <div class="ptitle">MeshLRM: Large Reconstruction Model for High-Quality Meshes</div>
                    <div class="pauthors">
                        Xinyue Wei*, Kai Zhang*, Sai Bi, Hao Tan, Fujun Luan, Valentin Deschaintre, Kalyan Sunkavalli, Hao Su, 
                        <b>Zexiang Xu</b>
                    </div>
                    <div class="pvenue">arXiv 2024</div>
                    <div class="plinks">
                            <a href="https://arxiv.org/abs/2404.12385">[Paper]</a>
                            <a href="https://sarahweiii.github.io/meshlrm/">[Project]</a>                            
                    </div>
                </div>
            </div>
            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    
                    <video width="75%" playsinline="" autoplay="" loop="" preload="" muted="">
                        <source src="papers/2024_neuralgaffer/neuralgafferr.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="description">
                    <div class="ptitle">Neural Gaffer: Relighting Any Object via Diffusion</div>
                    <div class="pauthors">
                        Haian Jin, Yuan Li, Fujun Luan, Yuanbo Xiangli, Sai Bi, Kai Zhang, <b>Zexiang Xu</b>, Jin Sun, Noah Snavely
                    </div>
                    <div class="pvenue">NeurIPS 2024</div>
                    <div class="plinks">
                            <a href="https://arxiv.org/abs/2406.07520">[Paper]</a>
                            <a href="https://neural-gaffer.github.io/">[Project]</a>                            
                    </div>
                </div>
            </div>

            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    
                    <img src="papers/2024_lrmzero/lrmzero.png">
                </div>
                <div class="description">
                    <div class="ptitle">LRM-Zero: Training Large Reconstruction Models with Synthesized Data</div>
                    <div class="pauthors">
                        Desai Xie, Sai Bi, Zhixin Shu, Kai Zhang, <b>Zexiang Xu</b>, Yi Zhou, Sören Pirk, Arie Kaufman, Xin Sun, Hao Tan
                    </div>
                    <div class="pvenue">NeurIPS 2024</div>
                    <div class="plinks">
                            <a href="https://arxiv.org/abs/2406.09371">[Paper]</a>
                            <a href="https://desaixie.github.io/lrm-zero/">[Project]</a>                            
                    </div>
                </div>
            </div>

            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    
                    <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                        <source src="papers/2024_DMesh/dmesh.mp4" type="video/mp4">
                    </video>
                    <!-- <img src="papers/2024_meshlrm/meshlrm.gif"> -->
                </div>
                <div class="description">
                    <div class="ptitle">DMesh: A Differentiable Mesh Representation</div>
                    <div class="pauthors">
                        Sanghyun Son, Matheus Gadelha, Yang Zhou, <b>Zexiang Xu</b>, Ming C. Lin, Yi Zhou
                    </div>
                    <div class="pvenue">NeurIPS 2024</div>
                    <div class="plinks">
                            <a href="https://arxiv.org/abs/2404.13445">[Paper]</a>
                            <a href="https://sonsang.github.io/dmesh-project/">[Project]</a>                            
                    </div>
                </div>
            </div>

            
            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    
                    <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                        <source src="papers/2024_gslrm/gslrm.mp4" type="video/mp4">
                    </video>
                    <!-- <img src="papers/2024_meshlrm/meshlrm.gif"> -->
                </div>
                <div class="description">
                    <div class="ptitle">GS-LRM: Large Reconstruction Model for 3D Gaussian Splatting</div>
                    <div class="pauthors">
                        Kai Zhang*, Sai Bi*, Hao Tan*, Yuanbo Xiangli, Nanxuan Zhao, Kalyan Sunkavalli,
                        <b>Zexiang Xu</b>
                    </div>
                    <div class="pvenue">ECCV 2024</div>
                    <div class="plinks">
                            <a href="https://arxiv.org/abs/2404.19702">[Paper]</a>
                            <a href="https://sai-bi.github.io/project/gs-lrm/">[Project]</a>                            
                    </div>
                </div>
            </div>
            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    
                    <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                        <source src="papers/2024_supergs/2024_supergs.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="description">
                    <div class="ptitle">SuperGaussian: Repurposing Video Models for 3D Super Resolution</div>
                    <div class="pauthors">
                        Yuan Shen, Duygu Ceylan, Paul Guerrero, <b>Zexiang Xu</b>, Niloy J. Mitra, Shenlong Wang, Anna Früshtück
                    </div>
                    <div class="pvenue">ECCV 2024</div>
                    <div class="plinks">
                            <a href="https://arxiv.org/abs/2406.00609">[Paper]</a>
                            <a href="https://supergaussian.github.io/">[Project]</a>                            
                    </div>
                </div>
            </div>
            
            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    
                    <video width="80%" playsinline="" autoplay="" loop="" preload="" muted="">
                        <source src="papers/2024_nde/nde.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="description">
                    <div class="ptitle">Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling</div>
                    <div class="pauthors">
                        Liwen Wu, Sai Bi, <b>Zexiang Xu</b>, Fujun Luan, Kai Zhang, Iliyan Georgiev, Kalyan Sunkavalli, Ravi Ramamoorthi
                    </div>
                    <div class="pvenue">CVPR 2024 (Highlight)</div>
                    <div class="plinks">
                            <a href="https://arxiv.org/abs/2405.14847">[Paper]</a>
                            <a href="https://lwwu2.github.io/nde/">[Project]</a>                            
                    </div>
                </div>
            </div>


            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    
                    <img src="papers/2024_dmv3d/dmv3d.gif">
                </div>
                <div class="description">
                    <div class="ptitle">DMV3D:Denoising Multi-View Diffusion using 3D Large Reconstruction Model</div>
                    <div class="pauthors">
                        Yinghao Xu, Hao Tan, Fujun Luan, Sai Bi, Peng Wang, Jiahao Li, Zifan Shi, Kalyan Sunkavalli, Gordon Wetzstein, <b>Zexiang Xu†</b>, Kai Zhang†
                    </div>
                    <div class="pvenue">ICLR 2024 (Spotlight)</div>
                    <div class="plinks">
                            <a href="https://arxiv.org/abs/2311.09217">[Paper]</a>
                            <a href="https://justimyhxu.github.io/projects/dmv3d/">[Project]</a>                            
                    </div>
                </div>
            </div>
            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    
                    <img src="papers/2024_pflrm/pflrm.gif">
                </div>
                <div class="description">
                    <div class="ptitle">PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction</div>
                    <div class="pauthors">
                        Peng Wang, Hao Tan, Sai Bi, Yinghao Xu, Fujun Luan, Kalyan Sunkavalli, Wenping Wang, <b>Zexiang Xu</b>, Kai Zhang
                    </div>
                    <div class="pvenue">ICLR 2024 (Spotlight)</div>
                    <div class="plinks">
                            <a href="https://arxiv.org/abs/2311.12024">[Paper]</a>
                            <a href="https://totoro97.github.io/pf-lrm/">[Project]</a>                            
                    </div>
                </div>
            </div>
            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    <!-- <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="papers/2024_instant3d/instant3d.mp4" type="video/mp4">
                    </video> -->
                    <img src="papers/2024_instant3d/instant3d.gif">
                </div>
                <div class="description">
                    <div class="ptitle">Instant3D: Fast Text-to-3D with Sparse-View Generation and Large Reconstruction Model</div>
                    <div class="pauthors">
                        Jiahao Li, Hao Tan, Kai Zhang, <b>Zexiang Xu</b>, Fujun Luan, Yinghao Xu, Yicong Hong, Kalyan Sunkavalli, Greg Shakhnarovich, Sai Bi
                    </div>
                    <div class="pvenue">ICLR 2024</div>
                    <div class="plinks">
                            <a href="https://arxiv.org/abs/2311.06214">[Paper]</a>
                            <a href="https://jiahao.ai/instant3d/">[Project]</a>                            
                    </div>
                </div>
            </div>
            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    <img src="papers/2024_movingparts/movingpart.gif">
                <!-- <img src="papers/2022_tensorf/icon.png"> -->
                </div>
                <div class="description">
                    <div class="ptitle">MovingParts: Motion-based Part Discovery in Dynamic Radiance Field</div>
                    <div class="pauthors">
                        Kaizhi Yang, Xiaoshuai Zhang, Zhiao Huang, Xuejin Chen, <b>Zexiang Xu†</b>, Hao Su†
                    </div>
                    <div class="pvenue">ICLR 2024 (Spotlight)</div>
                    <div class="plinks">
                            <a href="https://arxiv.org/abs/2303.05703">[Paper]</a>
                            <a href="https://silenkzyoung.github.io/MovingParts-WebPage/">[Project]</a>                            
                    </div>
                </div>
            </div>
            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    <img src="papers/2023_mcnerf/mcnerf.png">
                <!-- <img src="papers/2022_tensorf/icon.png"> -->
                </div>
                <div class="description">
                    <div class="ptitle">MCNeRF: Monte Carlo Rendering and Denoising for Real-Time NeRFs</div>
                    <div class="pauthors">
                        Kunal Gupta, Miloš Hašan, <b>Zexiang Xu</b>, Fujun Luan, Kalyan Sunkavalli, Xin Sun, Manmohan Chandraker, Sai Bi
                    </div>
                    <div class="pvenue">SIGGRAPH Asia 2023</div>
                    <div class="plinks">
                            <a href="https://drive.google.com/file/d/1WC70jMoaCSbVDxyJP0RfAuQJ9vieWnwI/view">[Paper]</a>
                            <a href="https://mcnerf.github.io/">[Project]</a>                            
                    </div>
                </div>
            </div>
            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    <img src="papers/2023_strivec/strivec.PNG">
                <!-- <img src="papers/2022_tensorf/icon.png"> -->
                </div>
                <div class="description">
                    <div class="ptitle">Strivec: Sparse Tri-Vector Radiance Fields</div>
                    <div class="pauthors">
                        Quankai Gao*, Qiangeng Xu*, Hao Su, Ulrich Neumann, <b>Zexiang Xu</b>
                    </div>
                    <div class="pvenue">ICCV 2023</div>
                    <div class="plinks">
                            <a href="https://arxiv.org/abs/2307.13226">[Paper]</a>
                            <a href="https://github.com/Zerg-Overmind/Strivec">[Code]</a>                            
                    </div>
                </div>
            </div>
    
            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    <img src="papers/2023_one2345/one2345.gif">
                <!-- <img src="papers/2022_tensorf/icon.png"> -->
                </div>
                <div class="description">
                    <div class="ptitle">One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization</div>
                    <div class="pauthors">
                        Minghua Liu*, Chao Xu*, Haian Jin*, Linghao Chen*, Mukund Varma T, <b>Zexiang Xu</b>, Hao Su
                    </div>
                    <div class="pvenue">NeurIPS 2023</div>
                    <div class="plinks">
                            <a href="https://one-2-3-45.github.io/">[Project]</a>
                            <a href="https://github.com/One-2-3-45/One-2-3-45">[Code]</a>                            
                    </div>
                </div>
            </div>
            
            <div class="paper">
                <div class="pimg">
                    <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                        <source src="papers/2023_DIF/DiF.mp4" type="video/mp4">
                    </video>
                <!-- <img src="papers/2022_tensorf/icon.png"> -->
                </div>
                <div class="description">
                    <div class="ptitle">Dictionary Fields: Learning a Neural Basis Decomposition</div>
                    <div class="pauthors">
                        Anpei Chen, <b>Zexiang Xu</b>,  Xinyue Wei, Siyu Tang, Hao Su, Andreas Geiger
                    </div>
                    <div class="pvenue">SIGGRAPH 2023 (Journal Track)</div>
                    <div class="plinks">
                            <a href="https://apchenstu.github.io/FactorFields/">[Project]</a>                            
                    </div>
                </div>
            </div>



            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    <img src="papers/2023_FactorFields/factorfields.png">
                </div>
                <div class="description">
                    <div class="ptitle">Factor Fields: A Unified Framework for Neural Fields and Beyond</div>
                    <div class="pauthors">
                        Anpei Chen, <b>Zexiang Xu</b>,  Xinyue Wei, Siyu Tang, Hao Su, Andreas Geiger
                    </div>
                    <div class="pvenue">arXiv 2023</div>
                    <div class="plinks">
                            <a href="https://apchenstu.github.io/FactorFields/">[Project]</a>
                            <a href="https://arxiv.org/abs/2302.01226">[Paper]</a>                            
                    </div>
                </div>
            </div>

            


            
            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    <img src="papers/2023_tensorir/tensoIR.gif" style="width: 70%;">
                </div>
                <div class="description">
                    <div class="ptitle">TensoIR: Tensorial Inverse Rendering</div>
                    <div class="pauthors">
                        Haian Jin*, Isabella Liu*, Peijia Xu, Xiaoshuai Zhang, Songfang Han, Sai Bi, Xiaowei Zhou, <b>Zexiang Xu†</b>,  Hao Su†
                    </div>
                    <div class="pvenue">CVPR 2023</div>
                    <div class="plinks">
                            <a href="https://haian-jin.github.io/TensoIR/">[Project]</a>
                            <a href="https://arxiv.org/abs/2304.12461">[Paper]</a>                            
                    </div>
                </div>
            </div>

            <div class="paper">
                <div class="pimg" style="display: flex; justify-content: center; align-items: center;">
                    <img src="papers/2023_renderdiffusion/renderdiffusion.png">
                <!-- <img src="papers/2022_tensorf/icon.png"> -->
                </div>
                <div class="description">
                    <div class="ptitle">RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation</div>
                    <div class="pauthors">
                        Titas Anciukevicius, <b>Zexiang Xu</b>,  Matthew Fisher, Paul Henderson, Hakan Bilen,  Niloy J. Mitra, Paul Guerrero
                    </div>
                    <div class="pvenue">CVPR 2023</div>
                    <div class="plinks">
                            <a href="https://github.com/Anciukevicius/RenderDiffusion">[Project]</a>
                            <a href="https://arxiv.org/abs/2211.09869">[Paper]</a>                            
                    </div>
                </div>
            </div>

            <div class="paper">
                <div class="pimg">
                    <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                        <source src="papers/2022_tensorf/tensorf.mp4" type="video/mp4">
                    </video>
                <!-- <img src="papers/2022_tensorf/icon.png"> -->
                </div>
                <div class="description">
                    <div class="ptitle">TensoRF: Tensorial Radiance fields</div>
                    <div class="pauthors">
                        <a href = "https://apchenstu.github.io/">Anpei Chen*</a>, <b>Zexiang Xu*</b>, Andreas Geiger, Jingyi Yu , Hao Su
                    </div>
                    <div class="pvenue">ECCV 2022</div>
                    <div class="plinks">
                            <a href="https://apchenstu.github.io/TensoRF/">[Project]</a>
                            <a href="https://arxiv.org/abs/2203.09517">[Paper]</a>                            
                    </div>
                </div>
            </div>
            <div class="paper">
                <div class="pimg">
                    <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                        <source src="papers/2022_arf/arf.mp4" type="video/mp4">
                    </video>
                <!-- <img src="papers/2022_tensorf/icon.png"> -->
                </div>
                <div class="description">
                    <div class="ptitle">ARF: Artistic Radiance Fields</div>
                    <div class="pauthors">
                        <a href = "https://kai-46.github.io/website/">Kai Zhang</a>, Nick Kolkin, Sai Bi, Fujun Luan, <b>Zexiang Xu</b>, Eli Shechtman, Noah Snavely
                    </div>
                    <div class="pvenue">ECCV 2022</div>
                    <div class="plinks">
                            <a href="https://www.cs.cornell.edu/projects/arf/">[Project]</a>
                            <a href="https://arxiv.org/abs/2206.06360">[Paper]</a>                            
                    </div>
                </div>
            </div>

            <div class="paper">
                <div class="pimg">
                    <img src="papers/2022_indoor/indoorelighting.png">
                <!-- <img src="papers/2022_tensorf/icon.png"> -->
                </div>
                <div class="description">
                    <div class="ptitle">Physically-based Editing of Indoor Scene Lighting from a Single Image</div>
                    <div class="pauthors">
                        <a href = "https://sites.google.com/a/eng.ucsd.edu/zhengqinli">Zhengqin Li</a>, Jia Shi, Sai Bi, Rui Zhu, Kalyan Sunkavalli, Miloš Hašan, <b>Zexiang Xu</b>, Ravi Ramamoorthi, Manmohan Chandraker
                    </div>
                    <div class="pvenue">ECCV 2022 (Oral)</div>
                    <div class="plinks">
                            <a href="https://vilab-ucsd.github.io/ucsd-IndoorLightEditing/">[Project]</a>
                            <a href="https://arxiv.org/abs/2205.09343">[Paper]</a>                            
                    </div>
                </div>
            </div>

            <div class="paper">
                <div class="pimg">
                    <img src="papers/2022_curved/curved.png">
                <!-- <img src="papers/2022_tensorf/icon.png"> -->
                </div>
                <div class="description">
                    <div class="ptitle">Rendering Neural Materials on Curved Surfaces</div>
                    <div class="pauthors">
                        Alexandr Kuznetsov, Xuezheng Wang, Krishna Mullia, Fujun Luan, <b>Zexiang Xu</b>, Miloš Hašan, Ravi Ramamoorthi
                    </div>
                    <div class="pvenue">SIGGRAPH 2022</div>
                    <div class="plinks">
                            <a href="https://cseweb.ucsd.edu/~viscomp/projects/CurvedNeuralMaterials/">[Project]</a>                           
                    </div>
                </div>
            </div>

            <div class="paper">
                <div class="pimg">
                <img src="papers/2022_nerfusion/icon.png">
                </div>
                <div class="description">
                    <div class="ptitle">NeRFusion: Fusing Radiance Fields for Large-Scale Scene Reconstruction</div>
                    <div class="pauthors">
                        <a href = "https://i.buriedjet.com/">Xiaoshuai Zhang</a>, Sai Bi, Kalyan Sunkavalli, Hao Su, <b>Zexiang Xu</b>
                    </div>
                    <div class="pvenue">CVPR 2022 (Oral)</div>
                    <div class="plinks">
                            <a href="https://jetd1.github.io/NeRFusion-Web/">[Project]</a>
                            <a href="https://arxiv.org/abs/2203.11283">[Paper]</a>                            
                    </div>
                </div>
            </div>

                <div class="paper">
                    <div class="pimg">
                    <img src="papers/2022_pointnerf/icon.jpg">
                    </div>
                    <div class="description">
                        <div class="ptitle">Point-NeRF: Point-based Neural Radiance Fields</div>
                        <div class="pauthors">
                            <a href = "https://xharlie.github.io/">Qiangeng Xu</a>, <b>Zexiang Xu</b>, Julien Philip, Sai Bi, Zhixin Shu
                            Kalyan Sunkavalli , Ulrich Neumann 
                        </div>
                        <div class="pvenue">CVPR 2022 (Oral)</div>
                        <div class="plinks">
                                <a href="https://xharlie.github.io/projects/project_sites/pointnerf/">[Project]</a>   
                                <a href="https://arxiv.org/abs/2201.08845">[Paper]</a>                           
                        </div>
                    </div>
                </div>
				<div class="paper">
                <div class="pimg">
				<img src="papers/2022_rignerf/rignerf.png">
               
                <!-- <img src="papers/2022_tensorf/icon.png"> -->
                </div>
                <div class="description">
                    <div class="ptitle">RigNeRF: Fully Controllable Neural 3D Portraits</div>
                    <div class="pauthors">
                        ShahRukh Athar, <b>Zexiang Xu</b>, Kalyan Sunkavalli, Eli Shechtman, Zhixin Shu
                    </div>
                    <div class="pvenue">CVPR 2022</div>
                    <div class="plinks">
                            <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Athar_RigNeRF_Fully_Controllable_Neural_3D_Portraits_CVPR_2022_paper.pdf">[Paper]</a>                            
                    </div>
                </div>
            </div>
				<div class="paper">
                <div class="pimg">
				<img src="papers/2022_photoscene/photoscene.jpg">
                
                <!-- <img src="papers/2022_tensorf/icon.png"> -->
                </div>
                <div class="description">
                    <div class="ptitle">PhotoScene: Photorealistic Material and Lighting Transfer for Indoor Scenes</div>
                    <div class="pauthors">
                        Yu-Ying Yeh, Zhengqin Li, Yannick Hold-Geoffroy, Rui Zhu, <b>Zexiang Xu</b>, Miloš Hašan, Kalyan Sunkavalli, Manmohan Chandraker
                    </div>
                    <div class="pvenue">CVPR 2022</div>
                    <div class="plinks">
                            <a href="https://openreview.net/pdf?id=KEZufsflq8p">[Paper]</a>                            
                    </div>
                </div>
            </div>

                <div class="paper">
                <div class="pimg">
                  <img src="papers/2021_mvsnerf/icon.gif">
                </div>
                <div class="description">
                    <div class="ptitle">MVSNeRF: Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo</div>
                    <div class="pauthors">
                        Anpei Chen*, <b>Zexiang Xu*</b>,  Fuqiang Zhao, <a href = "https://i.buriedjet.com/">Xiaoshuai Zhang</a>, <a href = "https://www.fbxiang.com/">Fanbo Xiang</a>, <a href = "http://www.yu-jingyi.com/">Jingyi Yu</a>, <a href = "https://cseweb.ucsd.edu/~haosu/">Hao Su</a> 
                    </div>
                    <div class="pvenue">ICCV 2021</div>
                    <div class="plinks">
                        
                            <a href="https://arxiv.org/abs/2103.15595">[arXiv]</a>
                        
                        
                            <a href="https://apchenstu.github.io/mvsnerf/">[Project]</a>

                        
                    </div>
                </div>
                
                </div>
                
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2021_NeLF/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">NeLF: Neural Light-transport Field for Portrait View Synthesis and Relighting</div>
                        <div class="pauthors">
                            <a href = "http://kevinkingo.com/">Tiancheng Sun*</a>, <a href = "https://cseweb.ucsd.edu/~k2lin/">Kai-En Lin*</a>,<a href = "http://cseweb.ucsd.edu/~bisai/">Sai Bi</a>, <b>Zexiang Xu</b>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a> 
                        </div>
                        <div class="pvenue">EGSR 2021</div>
                        <div class="plinks">
                                <a href="https://cseweb.ucsd.edu//~viscomp/projects/EGSR21NeLF/">[Project]</a>                            
                        </div>
                    </div>
                </div>
                
                <div class="paper">
                    <div class="pimg">
                        <img src="papers/2021_pathgraph/icon.png">
                    <!-- <img src="papers/2022_tensorf/icon.png"> -->
                    </div>
                    <div class="description">
                        <div class="ptitle">Path Graphs: Iterative Path Space Filtering</div>
                        <div class="pauthors">
                            <a href = "https://www.cs.cornell.edu/~xideng/">Xi Deng</a>,  Miloš Hašan, Nathan Carr, <b>Zexiang Xu</b>, Steve Marschner
                        </div>
                        <div class="pvenue">SIGGRAPH Asia 2021 (TOG)</div>
                        <div class="plinks">
                                <a href="https://www.cs.cornell.edu/~xideng/pub/deng21graph_small.pdf">[Paper]</a>                            
                        </div>
                    </div>
                </div>

                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2021_neumip/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">NeuMIP: Multi-Resolution Neural Materials</div>
                        <div class="pauthors">
                            <a href = "https://www.alexku.me">Alexandr Kuznetsov</a>, Krishna Mullia, <b>Zexiang Xu</b>, <a href = "http://www.miloshasan.net">Miloš Hašan</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a> 
                        </div>
                        <div class="pvenue">SIGGRAPH 2021 (TOG)</div>
                        <div class="plinks">                            
                                <a href="http://cseweb.ucsd.edu/~viscomp/projects/NeuMIP/">[Project]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2021_hierarchical/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">Hierarchical Neural Reconstruction for Path Guiding Using Hybrid Path and Photon Samples</div>
                        <div class="pauthors">
                            <a href = "https://cseweb.ucsd.edu/~shz338/">Shilin Zhu</a>, <b>Zexiang Xu</b>,<a href = "http://kevinkingo.com/">Tiancheng Sun</a>, <a href = "https://www.alexku.me">Alexandr Kuznetsov</a>, Mark Meyer, <a href = "http://graphics.ucsd.edu/~henrik/">Henrik Wann Jensen</a>, <a href = "https://cseweb.ucsd.edu/~haosu/">Hao Su</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a> 
                        </div>
                        <div class="pvenue">SIGGRAPH 2021 (TOG)</div>
                        <div class="plinks">                            
                                <a href="https://cseweb.ucsd.edu/~ravir/shilinsig21.pdf">[Paper]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2021_photonguiding/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">Photon-Driven Neural Path Guiding</div>
                        <div class="pauthors">
                            <a href = "https://cseweb.ucsd.edu/~shz338/">Shilin Zhu</a>, <b>Zexiang Xu</b>,<a href = "http://kevinkingo.com/">Tiancheng Sun</a>, <a href = "https://www.alexku.me">Alexandr Kuznetsov</a>, Mark Meyer, <a href = "http://graphics.ucsd.edu/~henrik/">Henrik Wann Jensen</a>, <a href = "https://cseweb.ucsd.edu/~haosu/">Hao Su</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
                        </div>
                        <div class="pvenue">TOG 2022</div>
                        <div class="plinks">                            
                            <a href="https://arxiv.org/abs/2010.01775">[arXiv]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2021_neutex/neutex.jpg">
                    </div>
                    <div class="description">
                        <div class="ptitle">NeuTex: Neural Texture Mapping for Volumetric Neural Rendering</div>
                        <div class="pauthors">
                            <a href = "https://www.fbxiang.com/">Fanbo Xiang</a>, <b>Zexiang Xu</b>,<a href = "http://www.miloshasan.net">Miloš Hašan</a>, <a href = "http://yannickhold.com/">Yannick Hold-Geoffroy</a>, <a href = "http://www.kalyans.org/">Kalyan Sunkavalli</a>, <a href = "https://cseweb.ucsd.edu/~haosu/">Hao Su</a>
                        </div>
                        <div class="pvenue">CVPR 2021 (Oral)</div>
                        <div class="plinks">                            
                            <a href="https://arxiv.org/abs/2103.00762">[arXiv]</a>
                            <a href="https://www.fbxiang.com/publications/neutex.html">[Project]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2021_openrooms/openrooms.jpg">
                    </div>
                    <div class="description">
                        <div class="ptitle">OpenRooms: An Open Framework for Photorealistic Indoor Scene Datasets</div>
                        <div class="pauthors">
                            <a href = "https://sites.google.com/a/eng.ucsd.edu/zhengqinli">Zhengqin Li</a>, Ting-Wei Yu, Shen Sang, Sarah Wang, Meng Song, Yuhan Liu, Yu-Ying Yeh, Rui Zhu, Nitesh Gundavarapu, Jia Shi, <a href = "http://cseweb.ucsd.edu/~bisai/">Sai Bi</a>, <b>Zexiang Xu</b>, Hong-Xing Yu, <a href = "http://www.kalyans.org/">Kalyan Sunkavalli</a>, <a href = "http://www.miloshasan.net">Miloš Hašan</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>, <a href = "http://vision.ucsd.edu/~manu/">Manmohan Chandraker</a>
                        </div>
                        <div class="pvenue">CVPR 2021 (Oral)</div>
                        <div class="plinks">                            
                            <a href="https://vilab-ucsd.github.io/ucsd-openrooms/">[Project]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2020_lightstage/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">Light stage super-resolution: continuous high-frequency relighting</div>
                        <div class="pauthors">
                            <a href = "http://kevinkingo.com/">Tiancheng Sun</a>, <b>Zexiang Xu</b>, <a href = "http://people.csail.mit.edu/xiuming/">Xiuming Zhang</a>, Sean Fanello, Christoph Rhemann, <a href = "https://www.pauldebevec.com/">Paul Debevec</a>, Yun-Ta Tsai, <a href = "https://jonbarron.info/">Jonathan T. Barron</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
                        </div>
                        <div class="pvenue">SIGGRAPH Asia 2020 (TOG)</div>
                        <div class="plinks">                            
                            <a href="http://cseweb.ucsd.edu/~viscomp/projects/SIGA20LightstageSuperres/">[Project]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2020_nrf/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">Neural Reflectance Fields for Appearance Acquisition</div>
                        <div class="pauthors">
                            <a href = "http://cseweb.ucsd.edu/~bisai/">Sai Bi*</a>, <b>Zexiang Xu*</b>, <a href = "http://people.eecs.berkeley.edu/~pratul/">Pratul P. Srinivasan</a>, <a href = "https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall</a>, <a href = "http://www.kalyans.org/">Kalyan Sunkavalli</a>, <a href = "http://www.miloshasan.net">Miloš Hašan</a>, <a href = "http://yannickhold.com/">Yannick Hold-Geoffroy</a>, <a href = "https://cseweb.ucsd.edu/~kriegman/">David Kriegman</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
                        </div>
                        <div class="pvenue">arXiv 2020</div>
                        <div class="plinks">                            
                            <a href="https://arxiv.org/abs/2008.03824">[arXiv]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2020_drv/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">Deep Reflectance Volumes: Relightable Reconstructions from Multi-View Photometric Images</div>
                        <div class="pauthors">
                            <a href = "http://cseweb.ucsd.edu/~bisai/">Sai Bi</a>, <b>Zexiang Xu</b>, <a href = "http://www.kalyans.org/">Kalyan Sunkavalli</a>, <a href = "http://www.miloshasan.net">Miloš Hašan</a>, <a href = "http://yannickhold.com/">Yannick Hold-Geoffroy</a>,   <a href = "https://cseweb.ucsd.edu/~kriegman/">David Kriegman</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
                        </div>
                        <div class="pvenue">ECCV 2020 (Spotlight)</div>
                        <div class="plinks">                            
                            <a href="https://arxiv.org/abs/2007.09892">[arXiv]</a>
                            <a href="https://cseweb.ucsd.edu/~ravir/saibi_eccv20.mp4">[video]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2020_mdp/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">Deep Multi Depth Panoramas for View Synthesis</div>
                        <div class="pauthors">
                            Kai-En Lin, <b>Zexiang Xu</b>, <a href = "https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall</a>, <a href = "http://people.eecs.berkeley.edu/~pratul/">Pratul P. Srinivasan</a>, <a href = "http://yannickhold.com/">Yannick Hold-Geoffroy</a>, <a href = "http://www.stephendiverdi.com/">Stephen DiVerdi</a>, <a href = "https://qisun.me/">Qi Sun</a>, <a href = "http://www.kalyans.org/">Kalyan Sunkavalli</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
                        </div>
                        <div class="pvenue">ECCV 2020</div>
                        <div class="plinks">                            
                            <a href="https://arxiv.org/abs/2008.01815">[arXiv]</a>
                            <a href="https://cseweb.ucsd.edu/~ravir/kaien_eccv20.mp4">[video]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2020_photon/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">Deep Kernel Density Estimation for Photon Mapping</div>
                        <div class="pauthors">
                            <a href = "https://cseweb.ucsd.edu/~shz338/">Shilin Zhu*</a>,  <b>Zexiang Xu*</b>, <a href = "http://graphics.ucsd.edu/~henrik/">Henrik Wann Jensen</a>, <a href = "https://cseweb.ucsd.edu/~haosu/">Hao Su</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
                        </div>
                        <div class="pvenue">EGSR 2020 (CGF journal track)</div>
                        <div class="plinks">                            
                            <a href="https://cseweb.ucsd.edu/~ravir/deepphotonegsr.pdf">[paper]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2020_atv/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">Deep Stereo using Adaptive Thin Volume Representation with Uncertainty Awareness</div>
                        <div class="pauthors">
                            <a href = "https://sites.google.com/view/shuocheng">Shuo Cheng*</a>,  <b>Zexiang Xu*</b>, <a href = "https://cseweb.ucsd.edu/~shz338/">Shilin Zhu</a>, Zhuwen Li, <a href = "http://www.cs.columbia.edu/~lierranli/">Li Erran Li</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>, <a href = "https://cseweb.ucsd.edu/~haosu/">Hao Su</a>
                        </div>
                        <div class="pvenue">CVPR 2020 (Oral)</div>
                        <div class="plinks">                            
                            <a href="https://arxiv.org/abs/1911.12012">[arXiv]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2020_deep3d/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">Deep 3D Capture: Geometry and Reflectance from Sparse Multi-View Images</div>
                        <div class="pauthors">
                            <a href = "http://cseweb.ucsd.edu/~bisai/">Sai Bi</a>, <b>Zexiang Xu</b>, <a href = "http://www.kalyans.org/">Kalyan Sunkavalli</a>, <a href = "https://cseweb.ucsd.edu/~kriegman/">David Kriegman</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
                        </div>
                        <div class="pvenue">CVPR 2020</div>
                        <div class="plinks">  
                            <a href="https://arxiv.org/abs/2003.12642">[arXiv]</a>                          
                            <a href="https://cseweb.ucsd.edu/~ravir/saibi_cvpr20.mp4">[video]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2019_gan/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">Learning Generative Models for Rendering Specular Microgeometry</div>
                        <div class="pauthors">
                            <a href = "https://www.alexku.me">Alexandr Kuznetsov</a>, <a href = "http://www.miloshasan.net">Miloš Hašan</a>,<b>Zexiang Xu</b>, <a href = "https://sites.cs.ucsb.edu/~lingqi/">Lingqi Yan</a>, <a href = "https://www.graphics.cornell.edu/~bjw/">Bruce Walter</a>, <a href = "http://faculty.cs.tamu.edu/nimak/">Nima Khademi Kalantari</a>, <a href = "http://www.cs.cornell.edu/~srm/">Steve Marschner</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
                        </div>
                        <div class="pvenue">SIGGRAPH Asia 2019 (TOG)</div>
                        <div class="plinks">  
                            <a href="https://cseweb.ucsd.edu/~ravir/alexgan.pdf">[arXiv]</a>                          
                            <a href="https://cseweb.ucsd.edu/~ravir/alexgan.mp4">[video]</a>
                        </div>
                    </div>
                </div>
                
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2019_viewsyn/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">Deep View Synthesis from Sparse Photometric Images</div>
                        <div class="pauthors">
                            <b>Zexiang Xu</b>, <a href = "http://cseweb.ucsd.edu/~bisai/">Sai Bi</a>, <a href = "http://www.kalyans.org/">Kalyan Sunkavalli</a>, <a href = "https://research.adobe.com/person/sunil-hadap/">Sunil Hadap</a>, <a href = "http://ai.ucsd.edu/~haosu/">Hao Su</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
                        </div>
                        <div class="pvenue">SIGGRAPH 2019 (TOG)</div>
                        <div class="plinks">  
                            <a href="papers/2019_viewsyn/2019_viewsyn_paper.pdf">[paper]</a>                          
                            <a href="https://cseweb.ucsd.edu/~ravir/zexiangview.mov">[video]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2019_portrait/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">Single Image Portrait Relighting</div>
                        <div class="pauthors">
                            <a href = "http://kevinkingo.com/">Tiancheng Sun</a>, <a href = "https://jonbarron.info/">Jonathan T. Barron</a>,
								Yun-Ta Tsai, <b>Zexiang Xu</b>, Xueming Yu, Graham Fyffe, Christoph Rhemann, Jay Busch, <a href = "https://www.pauldebevec.com/">Paul Debevec</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
                        </div>
                        <div class="pvenue">SIGGRAPH 2019 (TOG)</div>
                        <div class="plinks">  
                            <a href="papers/2019_portrait/2019_portrait_paper.pdf">[paper]</a>                          
                            <a href="https://cseweb.ucsd.edu/~ravir/portrait_relighting.m4v">[video]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2018_SVBRDF/icon.jpg">
                    </div>
                    <div class="description">
                        <div class="ptitle">Learning to Reconstruct Shape and Spatially-Varying Reflectance from a Single Image</div>
                        <div class="pauthors">
                            <a href = "https://sites.google.com/a/eng.ucsd.edu/zhengqinli/">Zhengqin Li</a>, <b>Zexiang Xu</b>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>, <a href = "http://www.kalyans.org/">Kalyan Sunkavalli</a>, <a href = "http://vision.ucsd.edu/~manu/">Manmohan Chandraker</a>
                        </div>
                        <div class="pvenue">SIGGRAPH Asia 2018 (TOG)</div>
                        <div class="plinks">  
                            <a href="papers/2018_SVBRDF/2018_svbrdf_paper.pdf">[paper]</a>                          
                            <a href="https://cseweb.ucsd.edu/~ravir/single-image-svbrdf.mov">[video]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2018_relighting/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">Deep Image-based Relighting from Optimal Sparse Samples</div>
                        <div class="pauthors">
                            <b>Zexiang Xu</b>, <a href = "http://www.eecs.harvard.edu/~kalyans/">Kalyan Sunkavalli</a>, <a href = "https://research.adobe.com/person/sunil-hadap/">Sunil Hadap</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
                        </div>
                        <div class="pvenue">SIGGRAPH 2018 (TOG)</div>
                        <div class="plinks">  
                            <a href="papers/2018_relighting/2018_relighting_paper.pdf">[paper]</a>                          
                            <a href="http://viscomp.ucsd.edu/projects/SIG18Relighting">[project]</a>
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2017_lightfield/icon.png">
                    </div>
                    <div class="description">
                        <div class="ptitle">Robust Energy Minimization for BRDF-Invariant Shape from Light Fields</div>
                        <div class="pauthors">
                            <a href = "https://sites.google.com/a/eng.ucsd.edu/zhengqinli/">Zhengqin Li</a>, <b>Zexiang Xu</b>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>, <a href = "http://vision.ucsd.edu/~manu/">Manmohan Chandraker</a>
                        </div>
                        <div class="pvenue">CVPR 2017</div>
                        <div class="plinks">  
                            <a href="papers/2017_lightfield/2017_lightfield_paper.pdf">[paper]</a>                          
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2016_nearfield/icon.jpg">
                    </div>
                    <div class="description">
                        <div class="ptitle">Minimal BRDF Sampling for Two-Shot Near-Field Reflectance Acquisition</div>
                        <div class="pauthors">
                            <b>Zexiang Xu</b>, Jannik Boll Nielsen, Jiyang Yu, <a href = "http://graphics.ucsd.edu/~henrik/">Henrik Wann Jensen</a>, <a href = "https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
                        </div>
                        <div class="pvenue">SIGGRAPH Asia 2016</div>
                        <div class="plinks">  
                            <a href="papers/2016_nearfield/2016_nearfield_paper.pdf">[paper]</a>                          
                        </div>
                    </div>
                </div>
                <div class="paper">
                    <div class="pimg">
                      <img src="papers/2014_hair/icon.jpg">
                    </div>
                    <div class="description">
                        <div class="ptitle">Dynamic Hair Capture using Spacetime Optimization</div>
                        <div class="pauthors">
                            <b>Zexiang Xu</b>, Hsiang-Tao Wu, <a href = "http://www.lvdiwang.com/">Lvdi Wang</a>, <a href = "http://www.cs.columbia.edu/~cxz/publications.htm">Changxi Zheng</a>, <a href = "http://research.microsoft.com/en-us/um/people/xtong/xtong.html">Xin Tong</a>, Yue Qi
                        </div>
                        <div class="pvenue">SIGGRAPH Asia 2014</div>
                        <div class="plinks">  
                            <a href="papers/2014_hair/2014_hair_paper.pdf">[paper]</a>
                            <a href="https://drive.google.com/file/d/1Tv3XvnAG0n6-ES1LtepPsPeTQB8ODQMZ/view?usp=sharing">[video]</a>                          
                        </div>
                    </div>
                </div>
                

                
            </div>

          
      </div>


      

    </div>
  

</body>